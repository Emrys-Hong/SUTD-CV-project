{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dDceLqL3HZ9p"
   },
   "source": [
    "# Download and install stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "siAmEc3oonfL",
    "outputId": "b39f1a74-e059-45cf-e9c6-afc701328923"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this model we train on all the train data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "id": "a-MMPbIuNMAJ",
    "outputId": "7fface64-df14-4526-9c90-caa4e3ad3b20"
   },
   "outputs": [],
   "source": [
    "!wget -c \"https://sutdapac-my.sharepoint.com/:u:/g/personal/gary_ong_mymail_sutd_edu_sg/EVrOU5p0-FhBggIuqB-rsCgBVzRTExFWLEjXdAVDwa1AQQ?e=FoLgld&download=1\" -O train_full.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 683
    },
    "colab_type": "code",
    "id": "NHTVSya3SCne",
    "outputId": "664a6df9-a558-435a-ecd0-ac64e09d6520"
   },
   "outputs": [],
   "source": [
    "!pip install -U git+https://github.com/albu/albumentations --no-cache-dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y0bLantMHwCV"
   },
   "source": [
    "# Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UaHtOHNYNqHR"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "class BengaliDataset2(Dataset):\n",
    "    def __init__(self,npy_file,label_csv,aug=None,norm=None):\n",
    "        self.npy_file = np.load(npy_file)\n",
    "        self.norm = norm\n",
    "        df = pd.read_csv(label_csv)\n",
    "        # for faster access i think\n",
    "        self.grapheme_root = df[\"grapheme_root\"].values\n",
    "        self.vowel_diacritic = df[\"vowel_diacritic\"].values\n",
    "        self.consonant_diacritic = df[\"consonant_diacritic\"].values\n",
    "\n",
    "        self.aug = aug\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_arr = self.npy_file[index]\n",
    "        # only do this on training\n",
    "        #use albumentations library\n",
    "        if self.aug != None:\n",
    "            image_arr = self.aug(image=image_arr)[\"image\"]\n",
    "\n",
    "        image_arr = (image_arr/255).astype(np.float32)\n",
    "        image_arr = torch.from_numpy(image_arr)\n",
    "\n",
    "        if self.norm != None:\n",
    "            mean = self.norm['mean']\n",
    "            std = self.norm['std']\n",
    "            image_arr = (image_arr -  mean)/std\n",
    "\n",
    "        grapheme_root = torch.Tensor([self.grapheme_root[index]]).long()\n",
    "        vowel_diacritic = torch.Tensor([self.vowel_diacritic[index]]).long()\n",
    "        consonant_diacritic = torch.Tensor([self.consonant_diacritic[index]]).long()\n",
    "        \n",
    "        return {\"image\":image_arr.unsqueeze(0).repeat(3, 1, 1),\"grapheme_root\":grapheme_root,\"vowel_diacritic\":vowel_diacritic,\"consonant_diacritic\":consonant_diacritic}\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.npy_file.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6fSyNFnnH6Sr"
   },
   "source": [
    "# Augmentations\n",
    "You can visualize some of the augmentations here: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1-qal9-GSX54R3Z0ZbZKGfS0b4k8FS1ji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g6zZuGQeRZ1r"
   },
   "outputs": [],
   "source": [
    "import albumentations\n",
    "\n",
    "mean = 13.4/255\n",
    "std = 40.8/255\n",
    "\n",
    "# shift_scale_rotate = A.augmentations.transforms.ShiftScaleRotate(p=0.75,scale_limit=0.4,rotate_limit=30)\n",
    "# brightness = A.augmentations.transforms.RandomBrightness(p=0.5)\n",
    "# grid_distortion = A.augmentations.transforms.GridDistortion(p=0.5,distort_limit=0.4)\n",
    "# blur = A.augmentations.transforms.Blur(p=0.2)\n",
    "# opticalDist = A.augmentations.transforms.OpticalDistortion(p=0.5)\n",
    "# elasticTransform = A.augmentations.transforms.ElasticTransform(p=0.5,alpha_affine=10)\n",
    "# downScale = A.augmentations.transforms.Downscale(p=0.5,scale_min=0.3,scale_max=0.5)\n",
    "# cutOut = A.augmentations.transforms.Cutout(p=1,num_holes=1,max_h_size=64,max_w_size=64)\n",
    "# gd = A.augmentations.transforms.GridDropout(unit_size_min=20,unit_size_max=100,p=0.5,random_offset=True)\n",
    "# gd2 = A.augmentations.transforms.GridDropout(unit_size_min=20,unit_size_max=100,p=0.75,fill_value=255,random_offset=True)\n",
    "# rgs = A.augmentations.transforms.RandomGridShuffle(p=1,grid=(2,2))\n",
    "# aug_list = [A.core.composition.OneOf([gd])]\n",
    "# augment = A.core.composition.Compose(aug_list,p=1)\n",
    "from albumentations.core.transforms_interface import ImageOnlyTransform\n",
    "from typing import Tuple, List, Dict\n",
    "class ImageTransformer:\n",
    "    \"\"\"\n",
    "    DataAugmentor for Image Classification.\n",
    "    Args:\n",
    "        data_augmentations: List of tuple(method: str, params :dict), each elems pass to albumentations\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_augmentations: List[Tuple[str, Dict]]):\n",
    "        \"\"\"Initialize.\"\"\"\n",
    "        augmentations_list = [\n",
    "            self._get_augmentation(aug_name)(**params)\n",
    "            for aug_name, params in data_augmentations]\n",
    "        self.data_aug = albumentations.Compose(augmentations_list)\n",
    "    \n",
    "    def __call__(self,image):\n",
    "        return self.data_aug(image=image)\n",
    "    \n",
    "    def __call2__(self, pair: Tuple[np.ndarray]) -> Tuple[np.ndarray]:\n",
    "        \"\"\"Forward\"\"\"\n",
    "        img_arr, label = pair\n",
    "        return self.data_aug(image=img_arr)[\"image\"], label\n",
    "\n",
    "    def _get_augmentation(self, aug_name: str) -> ImageOnlyTransform:\n",
    "        \"\"\"Get augmentations from albumentations\"\"\"\n",
    "        if hasattr(albumentations, aug_name):\n",
    "            return getattr(albumentations, aug_name)\n",
    "        else:\n",
    "            return eval(aug_name)\n",
    "        \n",
    "class RandomErasing(ImageOnlyTransform):\n",
    "    \"\"\"Class of RandomErase for Albumentations.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, s: Tuple[float]=(0.02, 0.4), r: Tuple[float]=(0.3, 2.7),\n",
    "        mask_value_min: int=0, mask_value_max: int=255,\n",
    "        always_apply: bool=False, p: float=1.0\n",
    "    ) -> None:\n",
    "        \"\"\"Initialize.\"\"\"\n",
    "        super().__init__(always_apply, p)\n",
    "        self.s = s\n",
    "        self.r = r\n",
    "        self.mask_value_min = mask_value_min\n",
    "        self.mask_value_max = mask_value_max\n",
    "\n",
    "    def apply(self, image: np.ndarray, **params):\n",
    "        \"\"\"\n",
    "        Apply transform.\n",
    "        Note: Input image shape is (Height, Width, Channel).\n",
    "        \"\"\"\n",
    "        image_copy = np.copy(image)\n",
    "\n",
    "        # # decide mask value randomly\n",
    "        mask_value = np.random.randint(self.mask_value_min, self.mask_value_max + 1)\n",
    "\n",
    "        h, w = image.shape\n",
    "        # # decide num of pixcels for mask.\n",
    "        mask_area_pixel = np.random.randint(h * w * self.s[0], h * w * self.s[1])\n",
    "\n",
    "        # # decide aspect ratio for mask.\n",
    "        mask_aspect_ratio = np.random.rand() * self.r[1] + self.r[0]\n",
    "\n",
    "        # # decide mask hight and width\n",
    "        mask_height = int(np.sqrt(mask_area_pixel / mask_aspect_ratio))\n",
    "        if mask_height > h - 1:\n",
    "            mask_height = h - 1\n",
    "        mask_width = int(mask_aspect_ratio * mask_height)\n",
    "        if mask_width > w - 1:\n",
    "            mask_width = w - 1\n",
    "\n",
    "        # # decide position of mask.\n",
    "        top = np.random.randint(0, h - mask_height)\n",
    "        left = np.random.randint(0, w - mask_width)\n",
    "        bottom = top + mask_height\n",
    "        right = left + mask_width\n",
    "        image_copy[top:bottom, left:right].fill(mask_value)\n",
    "\n",
    "        return image_copy\n",
    "    \n",
    "augment = ImageTransformer([('RandomErasing',{'p':0.5})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F72wJ7V5FF0W"
   },
   "outputs": [],
   "source": [
    "train_data = BengaliDataset2(\"train_full_128.npy\",\"train.csv\",aug =augment,norm={'mean':mean,'std':std})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1c4zrXnDJNOL"
   },
   "source": [
    "# Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zmJURapYS0k-"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import recall_score,confusion_matrix,ConfusionMatrixDisplay,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EWvUNbrrJjLO"
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, device, dataloaders, scheduler=None, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_recall = 0.0\n",
    "    \n",
    "    dataset_sizes = {'train': len(dataloaders['train'].dataset)}\n",
    "\n",
    "    train_acc_list = []; train_loss_list= []; val_acc_list = []; val_loss_list = []; unseen_acc_list = []; unseen_loss_list = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        start = time.time()\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train']:\n",
    "            \n",
    "            #used for calculating recall per epoch\n",
    "            grapheme_output = []\n",
    "            vowel_output = []\n",
    "            consonant_output = []\n",
    "            grapheme_label = []\n",
    "            vowel_label = []\n",
    "            consonant_label = []\n",
    "\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            grapheme_corrects = 0\n",
    "            vowel_corrects = 0\n",
    "            consonant_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for i,data in enumerate(dataloaders[phase]):\n",
    "\n",
    "                inputs = data['image']\n",
    "                grapheme_root_label = data['grapheme_root']\n",
    "                vowel_diacritic_label = data['vowel_diacritic']\n",
    "                consonant_diacritic_label = data['consonant_diacritic']\n",
    "                inputs = inputs.to(device)\n",
    "\n",
    "                grapheme_root_label =  grapheme_root_label.to(device)\n",
    "                vowel_diacritic_label = vowel_diacritic_label.to(device)\n",
    "                consonant_diacritic_label =  consonant_diacritic_label.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    g,v,c = model(inputs)\n",
    "                    \n",
    "                    grapheme_preds = g.argmax(dim=1)\n",
    "                    vowel_preds = v.argmax(dim=1) \n",
    "                    consonant_preds = c.argmax(dim=1)\n",
    "\n",
    "                    loss = criterion(g,v,c, grapheme_root_label.squeeze(1),vowel_diacritic_label.squeeze(1),consonant_diacritic_label.squeeze(1))\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                  \n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                #For accuracy\n",
    "                grapheme_corrects += torch.sum(grapheme_preds == grapheme_root_label.data.squeeze(1))\n",
    "                vowel_corrects += torch.sum(vowel_preds == vowel_diacritic_label.data.squeeze(1))\n",
    "                consonant_corrects += torch.sum(consonant_preds== consonant_diacritic_label.data.squeeze(1))\n",
    "\n",
    "                if phase == 'train':\n",
    "                  scheduler.step(epoch+i/dataset_sizes['train'])\n",
    "                \n",
    "            if phase == 'val' or phase == 'unseen':\n",
    "              grapheme_final_output = torch.cat(grapheme_output)    \n",
    "              grapheme_final_label =  torch.cat(grapheme_label)\n",
    "              \n",
    "              vowel_final_output = torch.cat(vowel_output)    \n",
    "              vowel_final_label =  torch.cat(vowel_label)\n",
    "              \n",
    "              consonant_final_output = torch.cat(consonant_output)    \n",
    "              consonant_final_label =  torch.cat(consonant_label)\n",
    "\n",
    "              grapheme_recall = recall_score(grapheme_final_output,grapheme_final_label,average='macro')\n",
    "              vowel_recall = recall_score(vowel_final_output,vowel_final_label,average='macro')\n",
    "              consonant_recall = recall_score(consonant_final_output,consonant_final_label,average='macro')\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            running_corrects = 0.5*grapheme_corrects.double() + 0.25*vowel_corrects.double() + 0.25*consonant_corrects.double()\n",
    "\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "\n",
    "            \n",
    "          \n",
    "            if phase == \"train\":\n",
    "                # Note this are running values (calculated per batch) rather than actual values at the end of each epoch\n",
    "                # Decreases training time\n",
    "                # Not accurate especially at first few epochs\n",
    "                train_acc_list.append(epoch_acc)\n",
    "                train_loss_list.append(epoch_loss)\n",
    "          \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            if (epoch==35 and i ==0)or (epoch==70 and i==0) or (epoch==104 and i==dataset_sizes['train']-1):\n",
    "                torch.save(model.state_dict(), \"model_epoch_\"+str(epoch)+\"iteration_\"+str(i)+\".pt\")\n",
    "\n",
    "        end = time.time()\n",
    "        print(f\"time per epoch:{end-start}s\")\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val recall: {:4f}'.format(best_recall))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    plots = (train_acc_list,train_loss_list,val_acc_list,val_loss_list,unseen_acc_list,unseen_loss_list)\n",
    "\n",
    "    return model, plots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_6AhzWBeJ95M"
   },
   "source": [
    "# Loss function and evaluate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zyPyPwDXJ0D7"
   },
   "outputs": [],
   "source": [
    "def loss(grapheme_root_output,vowel_diacritic_output,consonant_diacritic_output,grapheme_root_label,vowel_diacritic_label,consonant_diacritic_label):\n",
    "    gloss = nn.CrossEntropyLoss()(grapheme_root_output,grapheme_root_label)\n",
    "    vloss = nn.CrossEntropyLoss()(vowel_diacritic_output,vowel_diacritic_label)\n",
    "    closs = nn.CrossEntropyLoss()(consonant_diacritic_output,consonant_diacritic_label)\n",
    "\n",
    "    return 0.5*gloss + 0.25*vloss + 0.25*closs\n",
    "\n",
    "def evaluate_test(model,criterion,dataloader,device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    grapheme_corrects = 0.0\n",
    "    vowel_corrects = 0.0\n",
    "    consonant_corrects = 0.0\n",
    "    \n",
    "    grapheme_output = []\n",
    "    vowel_output = []\n",
    "    consonant_output = []\n",
    "\n",
    "    grapheme_label = []\n",
    "    vowel_label = []\n",
    "    consonant_label = []\n",
    "\n",
    "\n",
    "    for data in dataloader:\n",
    "\n",
    "        inputs = data['image']\n",
    "\n",
    "        grapheme_root_label = data['grapheme_root']\n",
    "        vowel_diacritic_label = data['vowel_diacritic']\n",
    "        consonant_diacritic_label = data['consonant_diacritic']\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        grapheme_root_label =  grapheme_root_label.to(device)\n",
    "        vowel_diacritic_label = vowel_diacritic_label.to(device)\n",
    "        consonant_diacritic_label =  consonant_diacritic_label.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            g,v,c = model(inputs)\n",
    "\n",
    "            loss = criterion(g,v,c, grapheme_root_label.squeeze(1),vowel_diacritic_label.squeeze(1),consonant_diacritic_label.squeeze(1))\n",
    "            grapheme_preds = g.argmax(dim=1)\n",
    "            vowel_preds = v.argmax(dim=1)\n",
    "            consonant_preds = c.argmax(dim=1)\n",
    "\n",
    "        # statistics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "\n",
    "        grapheme_corrects += torch.sum(grapheme_preds == grapheme_root_label.data.squeeze(1))\n",
    "        vowel_corrects += torch.sum(vowel_preds == vowel_diacritic_label.data.squeeze(1))\n",
    "        consonant_corrects += torch.sum(consonant_preds== consonant_diacritic_label.data.squeeze(1))\n",
    "        \n",
    "\n",
    "        grapheme_output.append(grapheme_preds.cpu())\n",
    "        grapheme_label.append(grapheme_root_label.data.squeeze(1).cpu())\n",
    "        vowel_output.append(vowel_preds.cpu())\n",
    "        vowel_label.append(vowel_diacritic_label.data.squeeze(1).cpu())\n",
    "        consonant_output.append(consonant_preds.cpu())\n",
    "        consonant_label.append(consonant_diacritic_label.data.squeeze(1).cpu())\n",
    "\n",
    "    grapheme_final_output = torch.cat(grapheme_output)    \n",
    "    grapheme_final_label =  torch.cat(grapheme_label)\n",
    "    \n",
    "    vowel_final_output = torch.cat(vowel_output)    \n",
    "    vowel_final_label =  torch.cat(vowel_label)\n",
    "    \n",
    "    consonant_final_output = torch.cat(consonant_output)    \n",
    "    consonant_final_label =  torch.cat(consonant_label)\n",
    "  \n",
    "\n",
    "    grapheme_recall = recall_score(grapheme_final_output,grapheme_final_label,average='macro')\n",
    "    vowel_recall = recall_score(vowel_final_output,vowel_final_label,average='macro')\n",
    "    consonant_recall = recall_score(consonant_final_output,consonant_final_label,average='macro')\n",
    "\n",
    "    print(\"grapheme recall:\",grapheme_recall)\n",
    "    print(\"vowel_recall:\",vowel_recall)\n",
    "    print(\"consonant_recall:\",consonant_recall)\n",
    "\n",
    "    print(\"final recall:\",0.5*grapheme_recall+0.25*vowel_recall+0.25*consonant_recall)\n",
    "\n",
    "    # print(classification_report(grapheme_final_label,grapheme_final_output))\n",
    "    # fig, axs = plt.subplots()\n",
    "    # fig.set_figheight(15)\n",
    "    # fig.set_figwidth(15)\n",
    "    # cm_vowel = confusion_matrix(grapheme_final_label,grapheme_final_output,normalize='true')\n",
    "    # cm = ConfusionMatrixDisplay(cm_vowel,[x for x in range(168)])\n",
    "    # cm.plot(ax=axs)\n",
    "\n",
    "\n",
    "    loss = running_loss / len(dataloader.dataset)\n",
    "\n",
    "    running_corrects = 0.5*grapheme_corrects.double() + 0.25*vowel_corrects.double() + 0.25*consonant_corrects.double()\n",
    "\n",
    "    # epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "    acc = running_corrects / len(dataloader.dataset)\n",
    "\n",
    "    print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "        \"Final Test Accuracy\", loss, acc))\n",
    "    return grapheme_final_output,grapheme_final_label,vowel_final_output,vowel_final_label,consonant_final_output,consonant_final_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jGHICZixJv0t"
   },
   "source": [
    "# Plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dRfFq4JSJubz"
   },
   "outputs": [],
   "source": [
    "def plot_model_metrics(plots,name):\n",
    "    train_acc_list,train_loss_list,val_acc_list,val_loss_list,test_acc_list,test_loss_list = plots\n",
    "    plot(train_acc_list,val_acc_list,test_acc_list,\"accuracy\",name)\n",
    "    plot(train_loss_list,val_loss_list,test_loss_list,\"loss\",name)\n",
    "\n",
    "\n",
    "def plot(train,val,test,metric,name):\n",
    "    plt.title(name)\n",
    "    plt.plot(train,label=\"train {}\".format(metric))\n",
    "    plt.plot(val,label=\"val {}\".format(metric))\n",
    "    plt.plot(test,label=\"test {}\".format(metric))\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.savefig(\"{}-{}\".format(name,metric))\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vnTQ8eYDKpIn"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretrainedmodels\n",
    "class SEModule(nn.Module):\n",
    "    def __init__(self, channels=2048, reduction=16):\n",
    "        super(SEModule, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Conv2d(channels, channels // reduction, kernel_size=1,\n",
    "                             padding=0)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Conv2d(channels // reduction, channels, kernel_size=1,\n",
    "                             padding=0)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        module_input = x\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return module_input * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gsD9uUvnKsIq"
   },
   "outputs": [],
   "source": [
    "# Easier to split stuff up and backpropagate\n",
    "class MyModel(nn.Module):\n",
    "  def __init__(self,pretrained=True):\n",
    "    super().__init__()\n",
    "    if pretrained:\n",
    "        self.model = pretrainedmodels.__dict__[\"se_resnext50_32x4d\"](pretrained=\"imagenet\")\n",
    "    else:\n",
    "        self.model = pretrainedmodels.__dict__[\"se_resnext50_32x4d\"](pretrained=None)\n",
    "    self.model = nn.Sequential(*list(self.model.children())[:-2])\n",
    "    \n",
    "    self.se_g = SEModule()\n",
    "    self.se_v = SEModule()\n",
    "    self.se_c = SEModule()\n",
    "    \n",
    "    self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "    \n",
    "    self.fc_g = nn.Sequential(nn.Linear(2048,2048), nn.ReLU(), nn.Dropout(p=0.5), nn.Linear(2048,168))\n",
    "    self.fc_v = nn.Sequential(nn.Linear(2048,2048), nn.ReLU(), nn.Dropout(p=0.5), nn.Linear(2048,11))\n",
    "    self.fc_c = nn.Sequential(nn.Linear(2048,2048), nn.ReLU(), nn.Dropout(p=0.5), nn.Linear(2048,7))\n",
    "    \n",
    "  def forward(self,x):\n",
    "    x = self.model(x)\n",
    "    \n",
    "    g = self.se_g(x)\n",
    "    v = self.se_v(x)\n",
    "    c = self.se_c(x)\n",
    "    \n",
    "    g = torch.flatten(self.avg_pool(g),1)\n",
    "    v = torch.flatten(self.avg_pool(v),1)\n",
    "    c = torch.flatten(self.avg_pool(c),1)\n",
    "    \n",
    "    g = self.fc_g(g)\n",
    "    v = self.fc_v(v)\n",
    "    c = self.fc_c(c)\n",
    "    return g,v,c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "1efded5d14ea4b1f9e789e6916c5ef83",
      "e1bc6a4df460400891cec8fbb840e9ab",
      "2bfcd7f7cffb4acfaef3099e747c44a4",
      "5ce852c0010843f7bf70ae915d9acbb8",
      "440e10a4689346d4a68a02e67abd0bd5",
      "b3e1f27f82b54742b7b5e5502be83328",
      "c98d5053c2ed44a5b77fca9b11a44f8d",
      "67e0308c7c0b4c349882b37daaac2f4f"
     ]
    },
    "colab_type": "code",
    "id": "ANlkaYkwcWTw",
    "outputId": "9f433c28-1de8-419f-9629-8400504fd631"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyModel(\n",
       "  (model): Sequential(\n",
       "    (0): Sequential(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (2): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (2): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (3): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (2): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (3): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (4): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (5): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (2): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (se_g): SEModule(\n",
       "    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       "  (se_v): SEModule(\n",
       "    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       "  (se_c): SEModule(\n",
       "    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       "  (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (fc_g): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=2048, out_features=168, bias=True)\n",
       "  )\n",
       "  (fc_v): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=2048, out_features=11, bias=True)\n",
       "  )\n",
       "  (fc_c): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=2048, out_features=7, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MyModel()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vp1uYB7FKFXQ"
   },
   "source": [
    "# Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zrr1IfwTVGSi"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=128, num_workers=4,shuffle=True)\n",
    "\n",
    "dataloaders = {'train': train_loader}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "nBsCIHZroSEq",
    "outputId": "f37365fe-6f02-482c-f0b1-6b79d02d6d1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/105\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "criterion = loss\n",
    "optimizer = optim.SGD(model.parameters(),lr=1.5e-02, momentum=0.9, weight_decay=1e-04, nesterov=True)\n",
    "# scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,mode='min',patience=3,factor=0.3,verbose=True)\n",
    "\n",
    "new_scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=35, T_mult=1, eta_min=0, last_epoch=-1)\n",
    "\n",
    "\n",
    "model,plots = train_model(model, criterion, optimizer,\n",
    "            device, dataloaders,scheduler=new_scheduler, num_epochs=105)\n",
    "\n",
    "\n",
    "# plot_model_metrics(plots,\"graph\")\n",
    "\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PdzNhxqp8pqq"
   },
   "outputs": [],
   "source": [
    " grapheme_final_output,grapheme_final_label,vowel_final_output,vowel_final_label,consonant_final_output,consonant_final_label = evaluate_test(model,criterion,val_loader,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pxeuRPqoXJH7"
   },
   "outputs": [],
   "source": [
    "grapheme_final_output,grapheme_final_label,vowel_final_output,vowel_final_label,consonant_final_output,consonant_final_label = evaluate_test(model,criterion,unseen_val_loader,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hmrpocq8HVJc"
   },
   "outputs": [],
   "source": [
    "#print(classification_report(grapheme_final_label,grapheme_final_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KYrzE8plp6bi"
   },
   "outputs": [],
   "source": [
    "plot_model_metrics(plots,\"graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q-ydXuT7qu--"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WCj2YcJmAVvD"
   },
   "outputs": [],
   "source": [
    "!cp graph-accuracy.png ./drive/'My Drive'/accuracy-graph.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JVlGoR9cAdMJ"
   },
   "outputs": [],
   "source": [
    "!cp graph-loss.png ./drive/'My Drive'/loss-graph.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t1Er1cE0Ae5R"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\"mynet.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hV70rb044OUV"
   },
   "outputs": [],
   "source": [
    "import pretrainedmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pretrainedmodels.__dict__['se_resnext50_32x4d'](pretrained='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = nn.Sequential(*list(model.children())[:-2])(torch.zeros((1,3,128,128)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem = SEModule()\n",
    "a = nn.AdaptiveAvgPool2d(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = a(sem(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.flatten(z,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "resnet-random-erase.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1efded5d14ea4b1f9e789e6916c5ef83": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2bfcd7f7cffb4acfaef3099e747c44a4",
       "IPY_MODEL_5ce852c0010843f7bf70ae915d9acbb8"
      ],
      "layout": "IPY_MODEL_e1bc6a4df460400891cec8fbb840e9ab"
     }
    },
    "2bfcd7f7cffb4acfaef3099e747c44a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b3e1f27f82b54742b7b5e5502be83328",
      "max": 87306240,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_440e10a4689346d4a68a02e67abd0bd5",
      "value": 87306240
     }
    },
    "440e10a4689346d4a68a02e67abd0bd5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "5ce852c0010843f7bf70ae915d9acbb8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_67e0308c7c0b4c349882b37daaac2f4f",
      "placeholder": "​",
      "style": "IPY_MODEL_c98d5053c2ed44a5b77fca9b11a44f8d",
      "value": " 83.3M/83.3M [43:31&lt;00:00, 33.4kB/s]"
     }
    },
    "67e0308c7c0b4c349882b37daaac2f4f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b3e1f27f82b54742b7b5e5502be83328": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c98d5053c2ed44a5b77fca9b11a44f8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e1bc6a4df460400891cec8fbb840e9ab": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
