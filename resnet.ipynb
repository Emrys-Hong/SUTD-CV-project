{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resnet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDceLqL3HZ9p",
        "colab_type": "text"
      },
      "source": [
        "# Download and install stuff"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "siAmEc3oonfL",
        "outputId": "a1b63687-61c2-4dcd-e14a-60b6bc34670f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Apr  8 12:10:53 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a-MMPbIuNMAJ",
        "outputId": "aa89969f-cc83-497c-c218-1be10560cb64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "!wget -c \"https://sutdapac-my.sharepoint.com/:u:/g/personal/gary_ong_mymail_sutd_edu_sg/EQGuIT9UUFlDv4IVasLW2dIBANJ5TPjK_hJfZ4yZS11LJQ?e=k6chXZ&download=1\" -O split-0.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-08 12:11:03--  https://sutdapac-my.sharepoint.com/:u:/g/personal/gary_ong_mymail_sutd_edu_sg/EQGuIT9UUFlDv4IVasLW2dIBANJ5TPjK_hJfZ4yZS11LJQ?e=k6chXZ&download=1\n",
            "Resolving sutdapac-my.sharepoint.com (sutdapac-my.sharepoint.com)... 13.107.136.9\n",
            "Connecting to sutdapac-my.sharepoint.com (sutdapac-my.sharepoint.com)|13.107.136.9|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /personal/gary_ong_mymail_sutd_edu_sg/Documents/BengaliDataset/split-0.zip?&originalPath=aHR0cHM6Ly9zdXRkYXBhYy1teS5zaGFyZXBvaW50LmNvbS86dTovZy9wZXJzb25hbC9nYXJ5X29uZ19teW1haWxfc3V0ZF9lZHVfc2cvRVFHdUlUOVVVRmxEdjRJVmFzTFcyZElCQU5KNVRQaktfaEpmWjR5WlMxMUxKUT9ydGltZT1JRm9LNmJYYjEwZw [following]\n",
            "--2020-04-08 12:11:04--  https://sutdapac-my.sharepoint.com/personal/gary_ong_mymail_sutd_edu_sg/Documents/BengaliDataset/split-0.zip?&originalPath=aHR0cHM6Ly9zdXRkYXBhYy1teS5zaGFyZXBvaW50LmNvbS86dTovZy9wZXJzb25hbC9nYXJ5X29uZ19teW1haWxfc3V0ZF9lZHVfc2cvRVFHdUlUOVVVRmxEdjRJVmFzTFcyZElCQU5KNVRQaktfaEpmWjR5WlMxMUxKUT9ydGltZT1JRm9LNmJYYjEwZw\n",
            "Reusing existing connection to sutdapac-my.sharepoint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1099653377 (1.0G) [application/x-zip-compressed]\n",
            "Saving to: ‘split-0.zip’\n",
            "\n",
            "split-0.zip         100%[===================>]   1.02G  68.4MB/s    in 22s     \n",
            "\n",
            "2020-04-08 12:11:27 (46.7 MB/s) - ‘split-0.zip’ saved [1099653377/1099653377]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "unYcjx-sNhqL",
        "outputId": "c1d007a4-397c-4ecb-ad23-c64a87b3fb58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "!wget -c \"https://sutdapac-my.sharepoint.com/:u:/g/personal/gary_ong_mymail_sutd_edu_sg/EbxFBne-jWFMuP1dYk6H_DgBV5IJLQPt2BYtNW8dv0PNew?e=761f5d&download=1\" -O unseen-val.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-08 12:11:32--  https://sutdapac-my.sharepoint.com/:u:/g/personal/gary_ong_mymail_sutd_edu_sg/EbxFBne-jWFMuP1dYk6H_DgBV5IJLQPt2BYtNW8dv0PNew?e=761f5d&download=1\n",
            "Resolving sutdapac-my.sharepoint.com (sutdapac-my.sharepoint.com)... 13.107.136.9\n",
            "Connecting to sutdapac-my.sharepoint.com (sutdapac-my.sharepoint.com)|13.107.136.9|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /personal/gary_ong_mymail_sutd_edu_sg/Documents/BengaliDataset/unseen-val.zip?&originalPath=aHR0cHM6Ly9zdXRkYXBhYy1teS5zaGFyZXBvaW50LmNvbS86dTovZy9wZXJzb25hbC9nYXJ5X29uZ19teW1haWxfc3V0ZF9lZHVfc2cvRWJ4RkJuZS1qV0ZNdVAxZFlrNkhfRGdCVjVJSkxRUHQyQll0Tlc4ZHYwUE5ldz9ydGltZT1vT21OLXJYYjEwZw [following]\n",
            "--2020-04-08 12:11:33--  https://sutdapac-my.sharepoint.com/personal/gary_ong_mymail_sutd_edu_sg/Documents/BengaliDataset/unseen-val.zip?&originalPath=aHR0cHM6Ly9zdXRkYXBhYy1teS5zaGFyZXBvaW50LmNvbS86dTovZy9wZXJzb25hbC9nYXJ5X29uZ19teW1haWxfc3V0ZF9lZHVfc2cvRWJ4RkJuZS1qV0ZNdVAxZFlrNkhfRGdCVjVJSkxRUHQyQll0Tlc4ZHYwUE5ldz9ydGltZT1vT21OLXJYYjEwZw\n",
            "Reusing existing connection to sutdapac-my.sharepoint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 42566918 (41M) [application/x-zip-compressed]\n",
            "Saving to: ‘unseen-val.zip’\n",
            "\n",
            "unseen-val.zip      100%[===================>]  40.59M  64.7MB/s    in 0.6s    \n",
            "\n",
            "2020-04-08 12:11:34 (64.7 MB/s) - ‘unseen-val.zip’ saved [42566918/42566918]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "b4NVJMYqRr8c",
        "outputId": "9298fdb4-9a01-4322-dab0-122c73ba43fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "!unzip split-0.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  split-0.zip\n",
            "  inflating: train-0.csv             \n",
            "  inflating: train-0.npy             \n",
            "  inflating: val-0.csv               \n",
            "  inflating: val-0.npy               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WihCkaRaBI60",
        "colab_type": "code",
        "outputId": "a7a06754-bfd4-4b3e-a49c-a9488049e88c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "!unzip unseen-val.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  unseen-val.zip\n",
            "  inflating: unseen-val.csv          \n",
            "  inflating: unseen-val.npy          \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgpDvjg4BPZu",
        "colab_type": "code",
        "outputId": "fa4c73fa-c8cf-4ee9-d9fd-dcbfbcfcd263",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data  train-0.csv  unseen-val.csv  unseen-val.zip  val-0.npy\n",
            "split-0.zip  train-0.npy  unseen-val.npy  val-0.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NHTVSya3SCne",
        "outputId": "ec41ea44-1203-4183-c7f7-83a9583ab108",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install -U git+https://github.com/albu/albumentations --no-cache-dir"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/albu/albumentations\n",
            "  Cloning https://github.com/albu/albumentations to /tmp/pip-req-build-9eo1t5b3\n",
            "  Running command git clone -q https://github.com/albu/albumentations /tmp/pip-req-build-9eo1t5b3\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.5) (1.18.2)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.5) (1.4.1)\n",
            "Collecting imgaug<0.2.7,>=0.2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/2e/748dbb7bb52ec8667098bae9b585f448569ae520031932687761165419a2/imgaug-0.2.6.tar.gz (631kB)\n",
            "\u001b[K     |████████████████████████████████| 634kB 1.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: PyYAML in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.5) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: opencv-python>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.5) (4.1.2.30)\n",
            "Requirement already satisfied, skipping upgrade: scikit-image>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (0.16.2)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (3.2.1)\n",
            "Requirement already satisfied, skipping upgrade: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (1.1.1)\n",
            "Requirement already satisfied, skipping upgrade: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (2.4.1)\n",
            "Requirement already satisfied, skipping upgrade: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (2.4)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (7.0.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (1.2.0)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (2.4.6)\n",
            "Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (4.4.2)\n",
            "Building wheels for collected packages: albumentations, imgaug\n",
            "  Building wheel for albumentations (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for albumentations: filename=albumentations-0.4.5-cp36-none-any.whl size=65099 sha256=f7ef4b6fe0ab2f57ef8e14706c4844d04c5b98b53f05859b4948109c36f94d43\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-z9qh3thm/wheels/45/8b/e4/2837bbcf517d00732b8e394f8646f22b8723ac00993230188b\n",
            "  Building wheel for imgaug (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imgaug: filename=imgaug-0.2.6-cp36-none-any.whl size=654020 sha256=5d6dc955dcc928a9fb8c3476bad55b4b8f98542bf898cce85edc834d70ec67f5\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-z9qh3thm/wheels/97/ec/48/0d25896c417b715af6236dbcef8f0bed136a1a5e52972fc6d0\n",
            "Successfully built albumentations imgaug\n",
            "Installing collected packages: imgaug, albumentations\n",
            "  Found existing installation: imgaug 0.2.9\n",
            "    Uninstalling imgaug-0.2.9:\n",
            "      Successfully uninstalled imgaug-0.2.9\n",
            "  Found existing installation: albumentations 0.1.12\n",
            "    Uninstalling albumentations-0.1.12:\n",
            "      Successfully uninstalled albumentations-0.1.12\n",
            "Successfully installed albumentations-0.4.5 imgaug-0.2.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0bLantMHwCV",
        "colab_type": "text"
      },
      "source": [
        "# Dataset class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UaHtOHNYNqHR",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "class BengaliDataset2(Dataset):\n",
        "    def __init__(self,npy_file,label_csv,aug=None,norm=None):\n",
        "        self.npy_file = np.load(npy_file)\n",
        "        self.norm = norm\n",
        "        df = pd.read_csv(label_csv)\n",
        "        # for faster access i think\n",
        "        self.grapheme_root = df[\"grapheme_root\"].values\n",
        "        self.vowel_diacritic = df[\"vowel_diacritic\"].values\n",
        "        self.consonant_diacritic = df[\"consonant_diacritic\"].values\n",
        "\n",
        "        self.aug = aug\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_arr = self.npy_file[index]\n",
        "        # only do this on training\n",
        "        #use albumentations library\n",
        "        if self.aug != None:\n",
        "            image_arr = self.aug(image=image_arr)[\"image\"]\n",
        "\n",
        "        image_arr = (image_arr/255).astype(np.float32)\n",
        "        image_arr = torch.from_numpy(image_arr)\n",
        "\n",
        "        if self.norm != None:\n",
        "            mean = self.norm['mean']\n",
        "            std = self.norm['std']\n",
        "            image_arr = (image_arr -  mean)/std\n",
        "\n",
        "        grapheme_root = torch.Tensor([self.grapheme_root[index]]).long()\n",
        "        vowel_diacritic = torch.Tensor([self.vowel_diacritic[index]]).long()\n",
        "        consonant_diacritic = torch.Tensor([self.consonant_diacritic[index]]).long()\n",
        "        \n",
        "        return {\"image\":image_arr.unsqueeze(0).repeat(3, 1, 1),\"grapheme_root\":grapheme_root,\"vowel_diacritic\":vowel_diacritic,\"consonant_diacritic\":consonant_diacritic}\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.npy_file.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fSyNFnnH6Sr",
        "colab_type": "text"
      },
      "source": [
        "# Augmentations\n",
        "You can visualize some of the augmentations here: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1-qal9-GSX54R3Z0ZbZKGfS0b4k8FS1ji)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g6zZuGQeRZ1r",
        "colab": {}
      },
      "source": [
        "import albumentations as A\n",
        "\n",
        "mean = 13.4/255\n",
        "std = 40.8/255\n",
        "\n",
        "# shift_scale_rotate = A.augmentations.transforms.ShiftScaleRotate(p=0.75,scale_limit=0.4,rotate_limit=30)\n",
        "# brightness = A.augmentations.transforms.RandomBrightness(p=0.5)\n",
        "# grid_distortion = A.augmentations.transforms.GridDistortion(p=0.5,distort_limit=0.4)\n",
        "# blur = A.augmentations.transforms.Blur(p=0.2)\n",
        "# opticalDist = A.augmentations.transforms.OpticalDistortion(p=0.5)\n",
        "# elasticTransform = A.augmentations.transforms.ElasticTransform(p=0.5,alpha_affine=10)\n",
        "downScale = A.augmentations.transforms.Downscale(p=0.5,scale_min=0.3,scale_max=0.5)\n",
        "cutOut = A.augmentations.transforms.Cutout(p=1,num_holes=1,max_h_size=64,max_w_size=64)\n",
        "gd = A.augmentations.transforms.GridDropout(unit_size_min=20,unit_size_max=100,p=0.5,random_offset=True)\n",
        "gd2 = A.augmentations.transforms.GridDropout(unit_size_min=20,unit_size_max=100,p=0.75,fill_value=255,random_offset=True)\n",
        "rgs = A.augmentations.transforms.RandomGridShuffle(p=1,grid=(2,2))\n",
        "aug_list = [A.core.composition.OneOf([gd])]\n",
        "augment = A.core.composition.Compose(aug_list,p=1)\n",
        "train_data = BengaliDataset2(\"train-0.npy\",\"train-0.csv\",aug =augment,norm={'mean':mean,'std':std})\n",
        "val_data = BengaliDataset2(\"val-0.npy\",\"val-0.csv\",norm={'mean':mean,'std':std})\n",
        "unseen_val = BengaliDataset2(\"unseen-val.npy\",\"unseen-val.csv\",norm={'mean':mean,'std':std})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c4zrXnDJNOL",
        "colab_type": "text"
      },
      "source": [
        "# Training function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zmJURapYS0k-",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import recall_score,confusion_matrix,ConfusionMatrixDisplay,classification_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWvUNbrrJjLO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, criterion, optimizer, device, dataloaders, scheduler=None, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_recall = 0.0\n",
        "    \n",
        "    dataset_sizes = {'train': len(dataloaders['train'].dataset),'val': len(dataloaders['val'].dataset),'unseen':len(dataloaders['unseen'].dataset)}\n",
        "\n",
        "    train_acc_list = []; train_loss_list= []; val_acc_list = []; val_loss_list = []; unseen_acc_list = []; unseen_loss_list = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        start = time.time()\n",
        "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val','unseen']:\n",
        "            \n",
        "            #used for calculating recall per epoch\n",
        "            grapheme_output = []\n",
        "            vowel_output = []\n",
        "            consonant_output = []\n",
        "            grapheme_label = []\n",
        "            vowel_label = []\n",
        "            consonant_label = []\n",
        "\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            grapheme_corrects = 0\n",
        "            vowel_corrects = 0\n",
        "            consonant_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for data in dataloaders[phase]:\n",
        "\n",
        "                inputs = data['image']\n",
        "                grapheme_root_label = data['grapheme_root']\n",
        "                vowel_diacritic_label = data['vowel_diacritic']\n",
        "                consonant_diacritic_label = data['consonant_diacritic']\n",
        "                inputs = inputs.to(device)\n",
        "\n",
        "                grapheme_root_label =  grapheme_root_label.to(device)\n",
        "                vowel_diacritic_label = vowel_diacritic_label.to(device)\n",
        "                consonant_diacritic_label =  consonant_diacritic_label.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    g,v,c = model(inputs)\n",
        "                    \n",
        "                    grapheme_preds = g.argmax(dim=1)\n",
        "                    vowel_preds = v.argmax(dim=1) \n",
        "                    consonant_preds = c.argmax(dim=1)\n",
        "\n",
        "                    loss = criterion(g,v,c, grapheme_root_label.squeeze(1),vowel_diacritic_label.squeeze(1),consonant_diacritic_label.squeeze(1))\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                  \n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                #For accuracy\n",
        "                grapheme_corrects += torch.sum(grapheme_preds == grapheme_root_label.data.squeeze(1))\n",
        "                vowel_corrects += torch.sum(vowel_preds == vowel_diacritic_label.data.squeeze(1))\n",
        "                consonant_corrects += torch.sum(consonant_preds== consonant_diacritic_label.data.squeeze(1))\n",
        "                if phase == 'val' or phase == 'unseen':\n",
        "                  #only do this for val and unseen because transfering to cpu is costly\n",
        "                  grapheme_output.append(grapheme_preds.cpu())\n",
        "                  grapheme_label.append(grapheme_root_label.data.squeeze(1).cpu())\n",
        "                  vowel_output.append(vowel_preds.cpu())\n",
        "                  vowel_label.append(vowel_diacritic_label.data.squeeze(1).cpu())\n",
        "                  consonant_output.append(consonant_preds.cpu())\n",
        "                  consonant_label.append(consonant_diacritic_label.data.squeeze(1).cpu())\n",
        "            if phase == 'val' or phase == 'unseen':\n",
        "              grapheme_final_output = torch.cat(grapheme_output)    \n",
        "              grapheme_final_label =  torch.cat(grapheme_label)\n",
        "              \n",
        "              vowel_final_output = torch.cat(vowel_output)    \n",
        "              vowel_final_label =  torch.cat(vowel_label)\n",
        "              \n",
        "              consonant_final_output = torch.cat(consonant_output)    \n",
        "              consonant_final_label =  torch.cat(consonant_label)\n",
        "\n",
        "              grapheme_recall = recall_score(grapheme_final_output,grapheme_final_label,average='macro')\n",
        "              vowel_recall = recall_score(vowel_final_output,vowel_final_label,average='macro')\n",
        "              consonant_recall = recall_score(consonant_final_output,consonant_final_label,average='macro')\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            running_corrects = 0.5*grapheme_corrects.double() + 0.25*vowel_corrects.double() + 0.25*consonant_corrects.double()\n",
        "\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects / dataset_sizes[phase]\n",
        "\n",
        "            if phase == 'val' and scheduler != None:\n",
        "                scheduler.step(epoch_loss)\n",
        "          \n",
        "            if phase == \"train\":\n",
        "                # Note this are running values (calculated per batch) rather than actual values at the end of each epoch\n",
        "                # Decreases training time\n",
        "                # Not accurate especially at first few epochs\n",
        "                train_acc_list.append(epoch_acc)\n",
        "                train_loss_list.append(epoch_loss)\n",
        "            elif phase == \"val\":\n",
        "                val_acc_list.append(epoch_acc)\n",
        "                val_loss_list.append(epoch_loss)\n",
        "            elif phase == \"unseen\":\n",
        "                unseen_acc_list.append(epoch_acc)\n",
        "                unseen_loss_list.append(epoch_loss)\n",
        "          \n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "            if phase == 'val' or phase == 'unseen':\n",
        "              total_recall = 0.5*grapheme_recall+0.25*vowel_recall+0.25*consonant_recall\n",
        "              print('Grapheme recall: {:.4f} Vowel recall: {:.4f} Consonant recall: {:.4f} Total Recall:{:.4f}'.\\\n",
        "                    format(grapheme_recall,vowel_recall,consonant_recall,total_recall))\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and total_recall > best_recall:\n",
        "                best_recall = total_recall\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "        end = time.time()\n",
        "        print(f\"time per epoch:{end-start}s\")\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    plots = (train_acc_list,train_loss_list,val_acc_list,val_loss_list,unseen_acc_list,unseen_loss_list)\n",
        "\n",
        "    return model, plots\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6AhzWBeJ95M",
        "colab_type": "text"
      },
      "source": [
        "# Loss function and evaluate function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyPyPwDXJ0D7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss(grapheme_root_output,vowel_diacritic_output,consonant_diacritic_output,grapheme_root_label,vowel_diacritic_label,consonant_diacritic_label):\n",
        "    gloss = nn.CrossEntropyLoss()(grapheme_root_output,grapheme_root_label)\n",
        "    vloss = nn.CrossEntropyLoss()(vowel_diacritic_output,vowel_diacritic_label)\n",
        "    closs = nn.CrossEntropyLoss()(consonant_diacritic_output,consonant_diacritic_label)\n",
        "\n",
        "    return 0.5*gloss + 0.25*vloss + 0.25*closs\n",
        "\n",
        "def evaluate_test(model,criterion,dataloader,device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    grapheme_corrects = 0.0\n",
        "    vowel_corrects = 0.0\n",
        "    consonant_corrects = 0.0\n",
        "    \n",
        "    grapheme_output = []\n",
        "    vowel_output = []\n",
        "    consonant_output = []\n",
        "\n",
        "    grapheme_label = []\n",
        "    vowel_label = []\n",
        "    consonant_label = []\n",
        "\n",
        "\n",
        "    for data in dataloader:\n",
        "\n",
        "        inputs = data['image']\n",
        "\n",
        "        grapheme_root_label = data['grapheme_root']\n",
        "        vowel_diacritic_label = data['vowel_diacritic']\n",
        "        consonant_diacritic_label = data['consonant_diacritic']\n",
        "\n",
        "        inputs = inputs.to(device)\n",
        "\n",
        "        grapheme_root_label =  grapheme_root_label.to(device)\n",
        "        vowel_diacritic_label = vowel_diacritic_label.to(device)\n",
        "        consonant_diacritic_label =  consonant_diacritic_label.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            g,v,c = model(inputs)\n",
        "\n",
        "            loss = criterion(g,v,c, grapheme_root_label.squeeze(1),vowel_diacritic_label.squeeze(1),consonant_diacritic_label.squeeze(1))\n",
        "            grapheme_preds = g.argmax(dim=1)\n",
        "            vowel_preds = v.argmax(dim=1)\n",
        "            consonant_preds = c.argmax(dim=1)\n",
        "\n",
        "        # statistics\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        \n",
        "\n",
        "        grapheme_corrects += torch.sum(grapheme_preds == grapheme_root_label.data.squeeze(1))\n",
        "        vowel_corrects += torch.sum(vowel_preds == vowel_diacritic_label.data.squeeze(1))\n",
        "        consonant_corrects += torch.sum(consonant_preds== consonant_diacritic_label.data.squeeze(1))\n",
        "        \n",
        "\n",
        "        grapheme_output.append(grapheme_preds.cpu())\n",
        "        grapheme_label.append(grapheme_root_label.data.squeeze(1).cpu())\n",
        "        vowel_output.append(vowel_preds.cpu())\n",
        "        vowel_label.append(vowel_diacritic_label.data.squeeze(1).cpu())\n",
        "        consonant_output.append(consonant_preds.cpu())\n",
        "        consonant_label.append(consonant_diacritic_label.data.squeeze(1).cpu())\n",
        "\n",
        "    grapheme_final_output = torch.cat(grapheme_output)    \n",
        "    grapheme_final_label =  torch.cat(grapheme_label)\n",
        "    \n",
        "    vowel_final_output = torch.cat(vowel_output)    \n",
        "    vowel_final_label =  torch.cat(vowel_label)\n",
        "    \n",
        "    consonant_final_output = torch.cat(consonant_output)    \n",
        "    consonant_final_label =  torch.cat(consonant_label)\n",
        "  \n",
        "\n",
        "    grapheme_recall = recall_score(grapheme_final_output,grapheme_final_label,average='macro')\n",
        "    vowel_recall = recall_score(vowel_final_output,vowel_final_label,average='macro')\n",
        "    consonant_recall = recall_score(consonant_final_output,consonant_final_label,average='macro')\n",
        "\n",
        "    print(\"grapheme recall:\",grapheme_recall)\n",
        "    print(\"vowel_recall:\",vowel_recall)\n",
        "    print(\"consonant_recall:\",consonant_recall)\n",
        "\n",
        "    print(\"final recall:\",0.5*grapheme_recall+0.25*vowel_recall+0.25*consonant_recall)\n",
        "\n",
        "    # print(classification_report(grapheme_final_label,grapheme_final_output))\n",
        "    # fig, axs = plt.subplots()\n",
        "    # fig.set_figheight(15)\n",
        "    # fig.set_figwidth(15)\n",
        "    # cm_vowel = confusion_matrix(grapheme_final_label,grapheme_final_output,normalize='true')\n",
        "    # cm = ConfusionMatrixDisplay(cm_vowel,[x for x in range(168)])\n",
        "    # cm.plot(ax=axs)\n",
        "\n",
        "\n",
        "    loss = running_loss / len(dataloader.dataset)\n",
        "\n",
        "    running_corrects = 0.5*grapheme_corrects.double() + 0.25*vowel_corrects.double() + 0.25*consonant_corrects.double()\n",
        "\n",
        "    # epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "    acc = running_corrects / len(dataloader.dataset)\n",
        "\n",
        "    print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "        \"Final Test Accuracy\", loss, acc))\n",
        "    return grapheme_final_output,grapheme_final_label,vowel_final_output,vowel_final_label,consonant_final_output,consonant_final_label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGHICZixJv0t",
        "colab_type": "text"
      },
      "source": [
        "# Plotting functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRfFq4JSJubz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_model_metrics(plots,name):\n",
        "    train_acc_list,train_loss_list,val_acc_list,val_loss_list,test_acc_list,test_loss_list = plots\n",
        "    plot(train_acc_list,val_acc_list,test_acc_list,\"accuracy\",name)\n",
        "    plot(train_loss_list,val_loss_list,test_loss_list,\"loss\",name)\n",
        "\n",
        "\n",
        "def plot(train,val,test,metric,name):\n",
        "    plt.title(name)\n",
        "    plt.plot(train,label=\"train {}\".format(metric))\n",
        "    plt.plot(val,label=\"val {}\".format(metric))\n",
        "    plt.plot(test,label=\"test {}\".format(metric))\n",
        "    plt.legend(loc=\"best\")\n",
        "    plt.savefig(\"{}-{}\".format(name,metric))\n",
        "    plt.close()\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnTQ8eYDKpIn",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsD9uUvnKsIq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Easier to split stuff up and backpropagate\n",
        "class MyModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    model = models.resnet18(pretrained=True)\n",
        "    self.model = nn.Sequential(*list(model.children())[:-1])#chop off last layer\n",
        "    self.fc_g = nn.Linear(512,168)\n",
        "    self.fc_v = nn.Linear(512,11)\n",
        "    self.fc_c = nn.Linear(512,7)\n",
        "  def forward(self,x):\n",
        "    x = self.model(x)\n",
        "    x = torch.flatten(x,1)\n",
        "    g = self.fc_g(x)\n",
        "    v = self.fc_v(x)\n",
        "    c = self.fc_c(x)\n",
        "    return g,v,c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ANlkaYkwcWTw",
        "outputId": "ea9e4ef1-8221-47f8-c207-50be52599d39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = MyModel()\n",
        "model.to(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MyModel(\n",
              "  (model): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (4): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (5): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (6): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (7): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  )\n",
              "  (fc_g): Linear(in_features=512, out_features=168, bias=True)\n",
              "  (fc_v): Linear(in_features=512, out_features=11, bias=True)\n",
              "  (fc_c): Linear(in_features=512, out_features=7, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vp1uYB7FKFXQ",
        "colab_type": "text"
      },
      "source": [
        "# Main Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Zrr1IfwTVGSi",
        "colab": {}
      },
      "source": [
        "train_loader = DataLoader(train_data, batch_size=128, num_workers=4,shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=128, num_workers=4)\n",
        "unseen_val_loader = DataLoader(unseen_val, batch_size=128, num_workers=4)\n",
        "\n",
        "dataloaders = {'train': train_loader,'val': val_loader,'unseen':unseen_val_loader}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nBsCIHZroSEq",
        "outputId": "b62d4b37-241f-4242-ecf6-cb8a4339c079",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "criterion = loss\n",
        "optimizer = optim.AdamW(model.parameters(),lr=1e-3)\n",
        "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,mode='min',patience=3,factor=0.3,verbose=True)\n",
        "\n",
        "model,plots = train_model(model, criterion, optimizer,\n",
        "            device, dataloaders,scheduler=scheduler, num_epochs=5)\n",
        "\n",
        "\n",
        "# plot_model_metrics(plots,\"graph\")\n",
        "\n",
        "\n",
        "print(\"done\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "----------\n",
            "train Loss: 0.1206 Acc: 0.9632\n",
            "val Loss: 0.1527 Acc: 0.9606\n",
            "Grapheme recall: 0.9401 Vowel recall: 0.9741 Consonant recall: 0.9680 Total Recall:0.9555\n",
            "unseen Loss: 0.9738 Acc: 0.7954\n",
            "Grapheme recall: 0.2402 Vowel recall: 0.7427 Consonant recall: 0.7858 Total Recall:0.5022\n",
            "time per epoch:130.44422364234924s\n",
            "Epoch 2/5\n",
            "----------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PdzNhxqp8pqq",
        "outputId": "ca7fd2ef-b2cb-4a7f-b697-b6f09989b718",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        " grapheme_final_output,grapheme_final_label,vowel_final_output,vowel_final_label,consonant_final_output,consonant_final_label = evaluate_test(model,criterion,val_loader,device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "grapheme recall: 0.9511877234680635\n",
            "vowel_recall: 0.9807612881598008\n",
            "consonant_recall: 0.9771203972475057\n",
            "final recall: 0.9650642830858583\n",
            "Final Test Accuracy Loss: 0.1303 Acc: 0.9653\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hmrpocq8HVJc",
        "colab": {}
      },
      "source": [
        "#print(classification_report(grapheme_final_label,grapheme_final_output))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KYrzE8plp6bi",
        "colab": {}
      },
      "source": [
        "plot_model_metrics(plots,\"graph\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q-ydXuT7qu--",
        "outputId": "d749db65-36a3-4993-9632-4e934d54b2aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WCj2YcJmAVvD",
        "colab": {}
      },
      "source": [
        "!cp graph-accuracy.png ./drive/'My Drive'/accuracy-graph.png"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JVlGoR9cAdMJ",
        "colab": {}
      },
      "source": [
        "!cp graph-loss.png ./drive/'My Drive'/loss-graph.png"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t1Er1cE0Ae5R",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(),\"mynet.pth\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hV70rb044OUV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}